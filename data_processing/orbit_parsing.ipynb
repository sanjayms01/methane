{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal:\n",
    "\n",
    "Parse the Google Doc that Jaclyn put together for all scanlines that run through California from `11/28/2018 - 10/01/2021`\n",
    "Save the output as a dictionary `{file_name: size_in_MB}`\n",
    "\n",
    "Google doc downloaded as a `.txt` file. Filename `ca_s5p_20181128_20211002.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import re\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import math\n",
    "\n",
    "\n",
    "role = get_execution_role()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_size(size_bytes):\n",
    "    if size_bytes == 0:\n",
    "        return \"0B\"\n",
    "    size_name = (\"B\", \"KB\", \"MB\", \"GB\", \"TB\", \"PB\", \"EB\", \"ZB\", \"YB\")\n",
    "    i = int(math.floor(math.log(size_bytes, 1024)))\n",
    "    p = math.pow(1024, i)\n",
    "    s = round(size_bytes / p, 2)\n",
    "    return \"%s %s\" % (s, size_name[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "83\n"
     ]
    }
   ],
   "source": [
    "file_test_string = 'S5P_OFFL_L2__CH4____20210930T183132_20210930T201301_20549_02_020200_20211002T102455'\n",
    "print(len(file_test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "size_test_string = 'Mission: Sentinel-5 P  Instrument: TROPOMI  Sensing Date: 2018-11-29T19:13:31.000Z  Size: 42.26 MB'\n",
    "print(len(size_test_string))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get all the filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './data_maps/ca_s5p_20181128_20211002.txt'\n",
    "\n",
    "#TOTAL count expected to be --> 1849\n",
    "file_names = []\n",
    "\n",
    "with open(file_name, mode='r', encoding='utf-8-sig') as file:\n",
    "    for ind, line in enumerate(file, 0):\n",
    "        line = line.strip()\n",
    "        #Using length to easily grab all the filenames\n",
    "        if len(line) == 83:\n",
    "            fn = line + '.nc'\n",
    "            cur_file_name = fn\n",
    "            file_names.append(cur_file_name)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the total data size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_sizes = []\n",
    "with open(file_name, mode='r', encoding='utf-8-sig') as file:\n",
    "    for ind, line in enumerate(file, 0):\n",
    "        line = line.strip()\n",
    "\n",
    "        #Using length to easily grab all the filenames\n",
    "        if \"Size:\" in line:\n",
    "            size = line.split(\":\")[-1].strip()\n",
    "            file_sizes.append(size)\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1849"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(file_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_ca_files = dict(zip(file_names, file_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_total = 0.0\n",
    "for k,v in all_ca_files.items():\n",
    "    size_total += float(v.split(\" \")[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92171.71000000006"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size_total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Total Data: `90-92gb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./data_maps/ca_filenames.pickle', 'wb') as handle:\n",
    "    pickle.dump(all_ca_files, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
